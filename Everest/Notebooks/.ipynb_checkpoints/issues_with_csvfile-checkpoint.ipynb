{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a2185e8-66a2-463d-8689-176157e292c5",
   "metadata": {},
   "source": [
    "The data was downloaded from github as a CSV and then was converted to UTF-8 on excel from UTF-16, however the data was corrupted. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e24978b-5ad5-40db-be91-93d845f78835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9a726762-4033-4504-9128-45d656b42767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPID            EVER20102,EVER,2020,1,Spring,2,China,N Col-NE ...\n",
      "PEAKID                                                         NaN\n",
      "YEAR                                                           NaN\n",
      "SEASON                                                         NaN\n",
      "SEASON_FACTOR                                                  NaN\n",
      "                                       ...                        \n",
      "PRIMRTE                                                        NaN\n",
      "PRIMMEM                                                        NaN\n",
      "PRIMREF                                                        NaN\n",
      "PRIMID                                                         NaN\n",
      "CHKSUM;                                                        NaN\n",
      "Name: 1, Length: 69, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv(\"exped_tidy_UTF-8.csv\", on_bad_lines='skip')\n",
    "df = pd.read_csv(\"exped_tidy_UTF-8.csv\")\n",
    "print(df['SMTDAYS'].head(10))\n",
    "\n",
    "row = df.iloc[1]\n",
    "print(row)\n",
    "\n",
    "df['SMTDAYS'] = pd.to_numeric(df['SMTDAYS'], errors='coerce')\n",
    "\n",
    "df_clean = df[(~df['SMTDAYS'].isna()) & (df['SMTDAYS']!=0)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "630e38c7-9f9b-4221-8af7-d2d62ff862ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan  0.]\n"
     ]
    }
   ],
   "source": [
    "df_clean\n",
    "print(df['SMTDAYS'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2280084c-aeb0-4c55-a1ae-d24ce89016c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: SMTDAYS, dtype: float64)\n"
     ]
    }
   ],
   "source": [
    "filtered = df.loc[(~df['SMTDAYS'].isna()) & (df['SMTDAYS'] != 0), 'SMTDAYS']\n",
    "print(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f5cb221-23b9-4740-ac6c-1550245d0369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [SMTDAYS]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(df_clean[['SMTDAYS']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f5a366c-a0d5-4c2a-be57-c72ccbeca091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "826\n",
      "52\n"
     ]
    }
   ],
   "source": [
    "print(df['SMTDAYS'].isna().sum())      # Number of NaN after conversion\n",
    "print((df['SMTDAYS'] == 0).sum())     # Number of zeros after conversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1ead10b-ffbc-44ea-ade2-30e0b2bfd605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "4    NaN\n",
      "5    NaN\n",
      "6    NaN\n",
      "7    NaN\n",
      "8    0.0\n",
      "9    NaN\n",
      "Name: SMTDAYS, dtype: float64\n",
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "4    NaN\n",
      "5    NaN\n",
      "6    NaN\n",
      "7    NaN\n",
      "8    0.0\n",
      "9    NaN\n",
      "Name: SMTDAYS_num, dtype: float64\n",
      "[nan  0.]\n",
      "[nan  0.]\n"
     ]
    }
   ],
   "source": [
    "# Show first 10 original values from SMTDAYS before conversion\n",
    "print(df['SMTDAYS'].head(10))\n",
    "\n",
    "# Show the same 10 values after conversion\n",
    "df['SMTDAYS_num'] = pd.to_numeric(df['SMTDAYS'], errors='coerce')\n",
    "print(df['SMTDAYS_num'].head(10))\n",
    "\n",
    "# Show unique values before and after conversion\n",
    "print(df['SMTDAYS'].unique())\n",
    "print(df['SMTDAYS_num'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f3f097a-8c6e-4498-bd63-ac389ce0c1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "4    NaN\n",
      "5    NaN\n",
      "6    NaN\n",
      "7    NaN\n",
      "8    0.0\n",
      "9    NaN\n",
      "Name: SMTDAYS, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['SMTDAYS'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "169a0e5f-a282-41e0-87e5-777a36d7f070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "4    NaN\n",
      "5    NaN\n",
      "6    NaN\n",
      "7    NaN\n",
      "8    0.0\n",
      "9    NaN\n",
      "Name: SMTDAYS, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df['SMTDAYS'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27776901-64a8-4192-a2a2-27e5ead01a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "4    NaN\n",
      "5    NaN\n",
      "6    NaN\n",
      "7    NaN\n",
      "8      0\n",
      "9    NaN\n",
      "Name: SMTDAYS, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv(\"exped_tidy_UTF-8.csv\", on_bad_lines='skip')\n",
    "print(df['SMTDAYS'].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f364ddc8-e1d7-4628-90b3-13f78bf700f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: SMTDAYS, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read CSV, skip problematic lines\n",
    "df = pd.read_csv(\"exped_tidy_UTF-8.csv\", on_bad_lines='skip')\n",
    "\n",
    "# Keep only rows where SMTDAYS is entirely numeric and not zero\n",
    "mask = df['SMTDAYS'].astype(str).str.isdigit() & (df['SMTDAYS'] != '0')\n",
    "usable_df = df[mask].copy()\n",
    "\n",
    "# Optionally convert SMTDAYS to integer type\n",
    "usable_df['SMTDAYS'] = usable_df['SMTDAYS'].astype(int)\n",
    "\n",
    "print(usable_df['SMTDAYS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "efe1a6ae-8d4d-48b6-ad21-cd75cba491ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: SMTDAYS, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"exped_tidy_UTF-8.csv\", on_bad_lines='skip')\n",
    "\n",
    "# Strip whitespace, check if string is digit, and not zero\n",
    "mask = df['SMTDAYS'].astype(str).str.strip().str.isdigit() & (df['SMTDAYS'].astype(str).str.strip() != '0')\n",
    "\n",
    "usable_df = df[mask].copy()\n",
    "usable_df['SMTDAYS'] = usable_df['SMTDAYS'].astype(int)\n",
    "\n",
    "print(usable_df['SMTDAYS'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8c49b4-6894-4fa8-ba04-c9caafb58e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['SMTDAYS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9876b3f2-cb42-4a53-bd36-b81e3863d802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: SMTDAYS_clean, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read only the first 10 rows for testing\n",
    "df = pd.read_csv(\"exped_tidy_UTF-8.csv\", nrows=10)\n",
    "\n",
    "# Remove leading/trailing whitespace and isolate numeric entries, excluding zero\n",
    "df['SMTDAYS_clean'] = df['SMTDAYS'].astype(str).str.strip()\n",
    "mask = df['SMTDAYS_clean'].str.isdigit() & (df['SMTDAYS_clean'] != '0')\n",
    "\n",
    "usable_subset = df[mask].copy()\n",
    "usable_subset['SMTDAYS_clean'] = usable_subset['SMTDAYS_clean'].astype(int)\n",
    "\n",
    "print(usable_subset['SMTDAYS_clean'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8cd235d7-2ba1-49ac-a2af-3d9aee6c24f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    NaN\n",
      "1    NaN\n",
      "2    NaN\n",
      "3    NaN\n",
      "4    NaN\n",
      "5    NaN\n",
      "6    NaN\n",
      "7    NaN\n",
      "8    0.0\n",
      "9    NaN\n",
      "Name: SMTDAYS, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"exped_tidy_UTF-8.csv\", nrows=10)\n",
    "print(df['SMTDAYS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4a827e9f-fc42-415a-9a84-c1db8524a3b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], Name: SMTDAYS_clean, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"exped_tidy_UTF-8.csv\", on_bad_lines='skip')\n",
    "\n",
    "# Clean whitespace and ensure you select only full numbers, not times (e.g., ignore 1300, 0615)\n",
    "df['SMTDAYS_clean'] = df['SMTDAYS'].astype(str).str.strip()\n",
    "# Use .isdigit() and length <= 2 to get only 1- or 2-digit valid days (adjust as needed)\n",
    "mask = df['SMTDAYS_clean'].str.isdigit() & (df['SMTDAYS_clean'] != '0') & (df['SMTDAYS_clean'].str.len() <= 2)\n",
    "usable_days = df.loc[mask, 'SMTDAYS_clean'].astype(int)\n",
    "\n",
    "print(usable_days)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e3c54e60-ecda-4916-ad91-2fc710be51d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"exped_tidy_UTF-8.csv\", on_bad_lines='skip')\n",
    "\n",
    "# Print the value in the SMTDAYS column of the third row (index 2)\n",
    "print(df.loc[2, 'SMTDAYS'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "63d820fb-2f0f-4d88-adf2-d2b567fd854a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     NaN\n",
      "1     NaN\n",
      "2     NaN\n",
      "3     NaN\n",
      "4     NaN\n",
      "5     NaN\n",
      "6     NaN\n",
      "7     NaN\n",
      "8       0\n",
      "9     NaN\n",
      "10    NaN\n",
      "11    NaN\n",
      "12    NaN\n",
      "13    NaN\n",
      "14    NaN\n",
      "Name: SMTDAYS, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"exped_tidy_UTF-8.csv\", on_bad_lines='skip')\n",
    "print(df['SMTDAYS'].head(15))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "77ded702-a791-439a-8899-17b3cffac2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   0       1     2       3   \\\n",
      "0                                               EXPID  PEAKID  YEAR  SEASON   \n",
      "1   EVER20101,EVER,2020,1,Spring,2,China,N Col-NE ...     NaN   NaN     NaN   \n",
      "2   EVER20102,EVER,2020,1,Spring,2,China,N Col-NE ...     NaN   NaN     NaN   \n",
      "3   EVER20103,EVER,2020,1,Spring,2,China,N Col-NE ...     NaN   NaN     NaN   \n",
      "4   AMAD20301,AMAD,2020,3,Autumn,1,Nepal,SW Ridge,...     NaN   NaN     NaN   \n",
      "5   AMAD20302,AMAD,2020,3,Autumn,1,Nepal,SW Ridge,...     NaN   NaN     NaN   \n",
      "6   AMAD20303,AMAD,2020,3,Autumn,1,Nepal,SW Ridge,...     NaN   NaN     NaN   \n",
      "7   AMAD20304,AMAD,2020,3,Autumn,1,Nepal,SW Ridge,...     NaN   NaN     NaN   \n",
      "8   AMAD20305,AMAD,2020,3,Autumn,1,Nepal,SW Ridge,...     NaN   NaN     NaN   \n",
      "9                                           AMAD20306    AMAD  2020       3   \n",
      "10  AMAD20307,AMAD,2020,3,Autumn,1,Nepal,SW Ridge,...     NaN   NaN     NaN   \n",
      "11  AMAD20401,AMAD,2020,4,Winter,1,Nepal,SW Ridge,...     NaN   NaN     NaN   \n",
      "12  BARU20301,BARU,2020,3,Autumn,1,Nepal,SE Ridge,...     NaN   NaN     NaN   \n",
      "13  CHOY20301,CHOY,2020,3,Autumn,2,China,NW side,N...     NaN   NaN     NaN   \n",
      "14  GYLZ20301,GYLZ,2020,3,Autumn,1,Nepal,SSE Face ...     NaN   NaN     NaN   \n",
      "\n",
      "               4     5            6         7       8       9   ...  \\\n",
      "0   SEASON_FACTOR  HOST  HOST_FACTOR    ROUTE1  ROUTE2  ROUTE3  ...   \n",
      "1             NaN   NaN          NaN       NaN     NaN     NaN  ...   \n",
      "2             NaN   NaN          NaN       NaN     NaN     NaN  ...   \n",
      "3             NaN   NaN          NaN       NaN     NaN     NaN  ...   \n",
      "4             NaN   NaN          NaN       NaN     NaN     NaN  ...   \n",
      "5             NaN   NaN          NaN       NaN     NaN     NaN  ...   \n",
      "6             NaN   NaN          NaN       NaN     NaN     NaN  ...   \n",
      "7             NaN   NaN          NaN       NaN     NaN     NaN  ...   \n",
      "8             NaN   NaN          NaN       NaN     NaN     NaN  ...   \n",
      "9          Autumn     1        Nepal  SW Ridge     NaN     NaN  ...   \n",
      "10            NaN   NaN          NaN       NaN     NaN     NaN  ...   \n",
      "11            NaN   NaN          NaN       NaN     NaN     NaN  ...   \n",
      "12            NaN   NaN          NaN       NaN     NaN     NaN  ...   \n",
      "13            NaN   NaN          NaN       NaN     NaN     NaN  ...   \n",
      "14            NaN   NaN          NaN       NaN     NaN     NaN  ...   \n",
      "\n",
      "           59          60                      61      62      63       64  \\\n",
      "0   ACCIDENTS  ACHIEVMENT                  AGENCY  COMRTE  STDRTE  PRIMRTE   \n",
      "1         NaN         NaN                     NaN     NaN     NaN      NaN   \n",
      "2         NaN         NaN                     NaN     NaN     NaN      NaN   \n",
      "3         NaN         NaN                     NaN     NaN     NaN      NaN   \n",
      "4         NaN         NaN                     NaN     NaN     NaN      NaN   \n",
      "5         NaN         NaN                     NaN     NaN     NaN      NaN   \n",
      "6         NaN         NaN                     NaN     NaN     NaN      NaN   \n",
      "7         NaN         NaN                     NaN     NaN     NaN      NaN   \n",
      "8         NaN         NaN                     NaN     NaN     NaN      NaN   \n",
      "9         NaN         NaN  Ever Quest Expeditions    TRUE   FALSE    FALSE   \n",
      "10        NaN         NaN                     NaN     NaN     NaN      NaN   \n",
      "11        NaN         NaN                     NaN     NaN     NaN      NaN   \n",
      "12        NaN         NaN                     NaN     NaN     NaN      NaN   \n",
      "13        NaN         NaN                     NaN     NaN     NaN      NaN   \n",
      "14        NaN         NaN                     NaN     NaN     NaN      NaN   \n",
      "\n",
      "         65       66      67       68  \n",
      "0   PRIMMEM  PRIMREF  PRIMID  CHKSUM;  \n",
      "1       NaN      NaN     NaN      NaN  \n",
      "2       NaN      NaN     NaN      NaN  \n",
      "3       NaN      NaN     NaN      NaN  \n",
      "4       NaN      NaN     NaN      NaN  \n",
      "5       NaN      NaN     NaN      NaN  \n",
      "6       NaN      NaN     NaN      NaN  \n",
      "7       NaN      NaN     NaN      NaN  \n",
      "8       NaN      NaN     NaN      NaN  \n",
      "9     FALSE    FALSE     NaN    4135;  \n",
      "10      NaN      NaN     NaN      NaN  \n",
      "11      NaN      NaN     NaN      NaN  \n",
      "12      NaN      NaN     NaN      NaN  \n",
      "13      NaN      NaN     NaN      NaN  \n",
      "14      NaN      NaN     NaN      NaN  \n",
      "\n",
      "[15 rows x 69 columns]\n"
     ]
    }
   ],
   "source": [
    "df_raw = pd.read_csv(\"exped_tidy_UTF-8.csv\", on_bad_lines='skip', header=None)\n",
    "print(df_raw.head(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5a6587e4-7a16-4d53-8548-134ea1051db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 2 is malformed: ['EVER20101,EVER,2020,1,Spring,2,China,N Col-NE Ridge,NA,NA,NA,China,Tibetan Rope-Fixing,Tibetan Rope-Fixing Everest North 2020,TRUE,FALSE,FALSE,FALSE,NA,NA,NA,NA,FALSE,FALSE,NA,Lhasa->Tingri->Everest BC,NA,2020-05-26,1515,0,0,NA,1,Success (main peak),NA,8849,FALSE,FALSE,FALSE,3,0,0,0,0,6,6,0,FALSE,TRUE,FALSE,TRUE,FALSE,TRUE,FALSE,FALSE,FALSE,NA,\"BC,ABC,C1,C2,C3,Smt(26/05)\",NA,NA,NA,Holy Mountain Adventure,TRUE,TRUE,FALSE,FALSE,FALSE,NA,2465291;']\n",
      "Row 3 is malformed: ['EVER20102,EVER,2020,1,Spring,2,China,N Col-NE Ridge,NA,NA,NA,China,Ci Luo (Tselo),Chinese Mount Everest Survey Team,TRUE,FALSE,FALSE,FALSE,NA,NA,NA,NA,FALSE,FALSE,NA,NA,NA,2020-05-27,0945,0,0,NA,1,Success (main peak),NA,8849,FALSE,FALSE,FALSE,3,0,12,8,0,0,0,0,FALSE,TRUE,FALSE,TRUE,FALSE,TRUE,FALSE,FALSE,FALSE,NA,\"BC,ABC,C1,C2,C3,Smt(27/05)\",221011,NA,NA,NA,TRUE,TRUE,FALSE,FALSE,FALSE,NA,2465292;']\n",
      "Row 4 is malformed: ['EVER20103,EVER,2020,1,Spring,2,China,N Col-NE Ridge,NA,NA,NA,China,Tsering Samdrup,Holy Mountain Adventure Everest Expedition 2020,TRUE,FALSE,FALSE,FALSE,NA,NA,NA,NA,FALSE,FALSE,NA,Lhasa->Tingri->Everest BC,2020-04-23,2020-05-28,0545,35,38,2020-05-31,1,Success (main peak),NA,8849,FALSE,FALSE,FALSE,3,0,20,14,0,22,21,0,FALSE,TRUE,FALSE,TRUE,FALSE,TRUE,FALSE,FALSE,FALSE,NA,\"BC(23/04,5200m),IC(26/04,5800m),ABC(05/01,6500m),C1(25/05,7028m),C2(26/05,7790m),C3(27/05,8300m),Smt(28/05)\",203869,NA,NA,Holy Mountain Adventure,TRUE,TRUE,FALSE,FALSE,FALSE,NA,2465293;']\n",
      "Row 5 is malformed: ['AMAD20301,AMAD,2020,3,Autumn,1,Nepal,SW Ridge,NA,NA,NA,Nepal,Chhang Dawa Sherpa,Seven Summit Treks Ama Dablam Expedition 2020,TRUE,FALSE,FALSE,FALSE,NA,NA,NA,NA,FALSE,FALSE,\"Canada, Czech Republic, France, Poland, Russia, Switzerland, Ukraine, USA\",NA,2020-11-09,2020-11-10,1300,1,0,NA,1,Success (main peak),NA,6814,FALSE,FALSE,FALSE,2,0,14,9,0,19,14,0,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,NA,\"BC(09/11,4450m),C1(5600m),C2(5900m),Smt(10,12-13,15/11)\",NA,NA,NA,Seven Summit Treks,TRUE,FALSE,FALSE,FALSE,FALSE,NA,2463299;']\n",
      "Row 6 is malformed: ['AMAD20302,AMAD,2020,3,Autumn,1,Nepal,SW Ridge,NA,NA,NA,USA,Garrett Madison,Madison Mountaineering Ama Dablam Expedition 2020,TRUE,FALSE,FALSE,FALSE,NA,NA,NA,NA,FALSE,FALSE,\"Canada, Qatar\",Lukla->Pangboche->Ama Dablam BC,2020-11-01,2020-11-10,1300,9,11,2020-11-12,1,Success (main peak),NA,6814,FALSE,FALSE,FALSE,2,0,6,6,0,8,8,0,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,NA,\"BC(01/11,4700m),C1(04/11,5600m),C2(10/11,6000m),Smt(10-11/11)\",29755,NA,NA,Himalayan Guides,TRUE,FALSE,FALSE,FALSE,FALSE,NA,2463299;']\n",
      "Row 7 is malformed: ['AMAD20303,AMAD,2020,3,Autumn,1,Nepal,SW Ridge,NA,NA,NA,UK,Jon Gupta,Himalayan Guides Ama Dablam Expedition 2020,TRUE,FALSE,FALSE,FALSE,NA,NA,NA,NA,FALSE,FALSE,NA,Lukla->Namche->Dingboche->Chhukung Ri->Pangboche->Ama Dablam BC,2020-11-15,2020-12-01,1243,16,17,2020-12-02,1,Success (main peak),NA,6814,FALSE,FALSE,FALSE,2,0,2,2,0,1,1,0,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,NA,\"BC(15/11,4400m),ABC(17/11,5350m),C1(18/11,5800m),C2(26/11,6000m),Smt(01/12)\",107752,NA,NA,Himalayan Guides,TRUE,FALSE,FALSE,FALSE,FALSE,NA,2463320;']\n",
      "Row 8 is malformed: ['AMAD20304,AMAD,2020,3,Autumn,1,Nepal,SW Ridge,NA,NA,NA,UK,\"Kenton Cool, Tim Mosedale\",Himalayan Guides Ama Dablam Expedition 2020,FALSE,FALSE,FALSE,FALSE,NA,NA,NA,NA,FALSE,FALSE,NA,Lukla->Namche->Dingboche->Chhukung Ri->Pangboche->Ama Dablam BC,2020-11-16,2020-11-27,NA,11,13,2020-11-29,4,\"Bad weather (storms, high winds)\",Abandoned at 6650m due to high winds,6650,FALSE,FALSE,FALSE,2,0,4,0,0,2,0,0,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,NA,\"BC(16/11,4500m),ABC(17/11/5400m),C1(19/12,5700m),C2(26/11,6000m),xxx(27/11,6650m)\",29661,NA,NA,Himalayan Guides,TRUE,FALSE,FALSE,FALSE,FALSE,NA,2463316;']\n",
      "Row 9 is malformed: ['AMAD20305,AMAD,2020,3,Autumn,1,Nepal,SW Ridge,NA,NA,NA,Italy,Manuel Villani,Furtenbach Adventures Ama Dablam Expedition 2020,TRUE,FALSE,FALSE,FALSE,NA,NA,NA,NA,FALSE,FALSE,NA,Lukla->Pangboche->Ama Dablam BC,2020-11-26,2020-11-29,0930,3,4,2020-11-30,1,Success (main peak),NA,6814,FALSE,FALSE,FALSE,2,0,1,1,0,1,1,0,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,NA,\"BC(26/11,4567m),C1(27/11,5700m),C2(28/11,5900m),Smt(29/11)\",17154,NA,NA,Iceland Trekking,TRUE,FALSE,FALSE,FALSE,FALSE,NA,2463318;']\n",
      "Row 10 SMTDAYS: 0\n",
      "Row 11 is malformed: ['AMAD20307,AMAD,2020,3,Autumn,1,Nepal,SW Ridge,NA,NA,NA,India,Debasish Biswas,Seven Summit Treks Ama Dablam Expedition 2020,TRUE,FALSE,FALSE,FALSE,NA,NA,NA,NA,FALSE,FALSE,\"Austria, UK\",Lukla->Pangboche->Ama Dablam BC,2020-11-20,2020-11-30,0615,10,0,NA,1,Success (main peak),NA,6814,FALSE,FALSE,FALSE,2,0,6,1,0,6,3,0,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,NA,\"BC(20/11,4450m),C1(5600m),C2(28/11,5900m),Smt(30/11)\",69150,NA,NA,Seven Summit Treks,TRUE,FALSE,FALSE,FALSE,FALSE,NA,2463318;']\n",
      "Row 12 is malformed: ['AMAD20401,AMAD,2020,4,Winter,1,Nepal,SW Ridge,NA,NA,NA,Nepal,Tashi Lakpa Sherpa,Seven Summit Treks Ama Dablam Expedition 2020,TRUE,FALSE,FALSE,FALSE,NA,NA,NA,NA,FALSE,FALSE,\"Egypt, India, Mexico, Oman, Qatar, Turkey\",NA,2020-12-27,2021-01-09,1410,13,0,NA,1,Success (main peak),NA,6814,FALSE,FALSE,FALSE,2,0,7,7,0,14,12,0,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,NA,\"BC(27/12,4450m),C1(5600m),C2(5900m),Smt(09,14/01)\",7722,NA,1st Arabic woman to summit Ama Dablam,Seven Summit Treks,TRUE,FALSE,FALSE,FALSE,FALSE,NA,2463359;']\n",
      "Row 13 is malformed: ['BARU20301,BARU,2020,3,Autumn,1,Nepal,SE Ridge,NA,NA,NA,Nepal,Dawa Steven Sherpa,Nepal Tourism Recovery Baruntse Expedition 2020,TRUE,FALSE,FALSE,FALSE,NA,NA,NA,NA,FALSE,FALSE,NA,NA,NA,2020-10-15,1215,0,0,NA,1,Success (main peak),NA,7152,FALSE,FALSE,FALSE,2,0,7,7,0,0,0,0,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,NA,\"BC,C1,C2,Smt(15/10)\",68764,NA,NA,Asian Trekking,FALSE,FALSE,FALSE,FALSE,FALSE,NA,2463723;']\n",
      "Row 14 is malformed: ['CHOY20301,CHOY,2020,3,Autumn,2,China,NW side,NA,NA,NA,China,Tsering Samdrup,Holy Mountain Adventure Cho Oyu Expedition 2020,TRUE,FALSE,FALSE,FALSE,NA,NA,NA,NA,FALSE,FALSE,NA,From Lhasa,2020-09-13,2020-09-29,1045,16,0,NA,1,Success (main peak),NA,8188,FALSE,FALSE,FALSE,2,0,20,19,0,24,24,0,FALSE,TRUE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,NA,\"BC(13/09),ABC(5700m),C1(6450m),C2(29/09,7100m),Smt(29-30/09)\",220925,NA,NA,Holy Mountain Adventure,TRUE,TRUE,FALSE,FALSE,FALSE,NA,2464202;']\n",
      "Row 15 is malformed: ['GYLZ20301,GYLZ,2020,3,Autumn,1,Nepal,SSE Face from SW,NA,NA,NA,Nepal,Sharmila Lama Tamang,Jugal Expedition 2020,TRUE,FALSE,FALSE,FALSE,2nd,NA,NA,NA,FALSE,FALSE,NA,NA,2020-10-17,2020-10-19,NA,2,0,NA,1,Success (main peak),NA,6151,FALSE,FALSE,FALSE,1,0,3,2,0,3,3,0,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,NA,\"BC(17/10),C1(18/10),Smt(19/10)\",29593,NA,NA,Soul Himalaya,FALSE,FALSE,FALSE,FALSE,FALSE,NA,2461207;']\n",
      "Row 16 is malformed: ['HIML20301,HIML,2020,3,Autumn,1,Nepal,W Ridge,NA,NA,NA,Nepal,Pasang Tendi Sherpa,TAGnepal Himlung Expedition 2020,FALSE,FALSE,FALSE,FALSE,NA,NA,NA,NA,FALSE,FALSE,\"Italy, Jordan, UAE, UK\",NA,2020-11-03,2020-11-17,NA,14,0,NA,4,\"Bad weather (storms, high winds)\",Abandoned at C3 due to bad weather,6400,FALSE,FALSE,FALSE,3,0,5,0,0,0,0,0,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,NA,\"BC(03/11,5200m),C1,C2,C3(17/11,6400m),xxx\",NA,NA,NA,TAGnepal Trekking,FALSE,FALSE,FALSE,FALSE,FALSE,NA,2461326;']\n",
      "Row 17 is malformed: ['HIML20302,HIML,2020,3,Autumn,1,Nepal,W Ridge,NA,NA,NA,Romania,Marius-Sebastian Purice,High Himalayan Romanian Himlung Himal Expedition 2020,TRUE,FALSE,FALSE,FALSE,NA,NA,NA,NA,FALSE,FALSE,NA,Koto->Phu->BC,2020-11-15,2020-11-29,1326,14,16,2020-12-01,1,Success (main peak),NA,7126,FALSE,FALSE,FALSE,2,0,1,1,0,4,4,0,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,NA,\"BC(15/11,4900m),C1(19/11,5400m),C2(21/11,6100m),Smt(29/11)\",11450,NA,NA,High Himalayan Climbing,FALSE,FALSE,FALSE,FALSE,FALSE,NA,2461338;']\n",
      "Row 18 is malformed: ['KYR220401,KYR2,2020,4,Winter,1,Nepal,SW Face-SE Ridge,NA,NA,NA,Switzerland,Sophie Lavaud,Seven Summit Treks Kyungka Ri 2 Expedition 2020,TRUE,FALSE,FALSE,FALSE,1st,NA,NA,NA,FALSE,FALSE,NA,NA,NA,2020-12-11,1040,0,0,NA,1,Success (main peak),NA,6506,FALSE,FALSE,FALSE,2,0,1,1,0,3,3,0,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,NA,\"BC,C1(09/12,5309m),C2(10/12,5630m),Smt(11/12)\",13113,NA,NA,Seven Summit Treks,FALSE,FALSE,FALSE,FALSE,FALSE,NA,2461620;']\n",
      "Row 19 is malformed: ['LUZA20401,LUZA,2020,4,Winter,1,Nepal,NE Face,SE Face,NA,NA,Nepal,Pemba Sherpa,\"Luza 5726m, First Ascent Expedition 2020\",FALSE,TRUE,FALSE,FALSE,1st,NA,NA,NA,FALSE,FALSE,NA,NA,NA,2020-12-17,1215,0,0,NA,1,Success (main peak),NA,5710,FALSE,FALSE,FALSE,0,0,3,3,0,0,0,0,TRUE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,NA,Smt(17/12),2195,NA,NA,Xtreme Climbers,FALSE,FALSE,FALSE,FALSE,FALSE,NA,2461896;']\n",
      "Row 20 is malformed: ['MANA20301,MANA,2020,3,Autumn,1,Nepal,NE Face,NA,NA,NA,Bahrain,\"Mohamed Hamed Mohamed Al Khalifa, Christopher Burrows\",Bahrain Royal Guard Manaslu Expedition 2020,TRUE,FALSE,FALSE,FALSE,NA,NA,NA,NA,FALSE,FALSE,UK,NA,2020-10-08,2020-10-15,0630,7,0,NA,1,Success (main peak),NA,8163,FALSE,FALSE,FALSE,3,0,18,13,0,52,43,0,FALSE,TRUE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,Climbed Lobuche for acclimatization on 3 Oct,\"BC(08/10),C1,C2,C3(14/10),Smt(15/10)\",12965,NA,NA,Seven Summit Treks,TRUE,TRUE,FALSE,FALSE,FALSE,NA,2462238;']\n",
      "Row 21 is malformed: ['MANA20401,MANA,2020,4,Winter,1,Nepal,NE Face,NA,NA,NA,Italy,Simone Moro,Italian-Spanish Manaslu Winter Expedition 2020-2021,FALSE,FALSE,FALSE,FALSE,NA,NA,NA,NA,FALSE,FALSE,Spain,Samagaon by helicopter,2021-01-10,NA,NA,0,0,NA,5,\"Bad conditions (deep snow, avalanching, falling ice, or rock)\",Abandoned at 7050m due to deep snow and dangerous conditions,7050,FALSE,FALSE,FALSE,2,0,3,0,0,4,0,0,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,NA,\"BC(10/01,4800m),C1(5700m),C2(6550m),xxx(7050m)\",NA,NA,NA,Seven Summit Treks,TRUE,TRUE,FALSE,FALSE,FALSE,NA,3100;']\n",
      "Row 22 is malformed: ['MANA20402,MANA,2020,4,Winter,1,Nepal,NE Face,NA,NA,NA,Nepal,Vinayak Jaya Malla,Nepalese Manaslu Winter Expedition 2020-2021,FALSE,FALSE,FALSE,FALSE,NA,NA,NA,NA,FALSE,FALSE,NA,NA,NA,NA,NA,0,0,NA,5,\"Bad conditions (deep snow, avalanching, falling ice, or rock)\",Abandoned due to deep snow and dangerous conditions,6550,FALSE,FALSE,FALSE,2,0,2,0,0,0,0,0,TRUE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,NA,\"BC,C1,C2,xxx(6550m)\",NA,NA,NA,Seven Summit Treks,TRUE,TRUE,FALSE,FALSE,FALSE,NA,3100;']\n",
      "Row 23 is malformed: ['AMAD21101,AMAD,2021,1,Spring,1,Nepal,SW Ridge,NA,NA,NA,Italy,Giampaolo Corona,Seven Summit Treks International Ama Dablam Expedition 2021,TRUE,FALSE,FALSE,FALSE,NA,NA,NA,NA,FALSE,FALSE,\"Ecuador, Finland, Germany, India, Iraq, Israel, Jordan, Kenya, Kyrgyz Republic, Nepal, Norway, Romania, Russia\",NA,NA,2021-04-28,1145,0,0,NA,1,Success (main peak),NA,6814,FALSE,FALSE,FALSE,2,0,16,8,0,4,1,0,FALSE,FALSE,TRUE,FALSE,FALSE,FALSE,FALSE,FALSE,FALSE,NA,Smt(28-30/04),207515,NA,NA,Seven Summit Treks,TRUE,FALSE,FALSE,FALSE,FALSE,NA,2464594;']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "with open(\"exped_tidy_UTF-8.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    header = next(reader)\n",
    "    if \"SMTDAYS\" in header:\n",
    "        smtdays_idx = header.index(\"SMTDAYS\")\n",
    "    else:\n",
    "        print(\"SMTDAYS not found in header!\")\n",
    "        smtdays_idx = None\n",
    "\n",
    "    for i, row in enumerate(reader):\n",
    "        # print as many rows as needed to confirm correct access\n",
    "        if smtdays_idx is not None and len(row) > smtdays_idx:\n",
    "            print(f\"Row {i+2} SMTDAYS:\", row[smtdays_idx])\n",
    "        else:\n",
    "            print(f\"Row {i+2} is malformed:\", row)\n",
    "        if i > 20:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b8d28b1-a1c4-4d7d-addc-2df4031fe72c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'exped_tidy.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mexped_tidy.csv\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlatin1\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# or 'windows-1252', etc.\u001b[39;00m\n\u001b[32m      4\u001b[39m df.to_csv(\u001b[33m'\u001b[39m\u001b[33mexped_tidy_utf8.csv\u001b[39m\u001b[33m'\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'exped_tidy.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('exped_tidy.csv', encoding='latin1')  # or 'windows-1252', etc.\n",
    "df.to_csv('exped_tidy_utf8.csv', index=False, encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d06f7f-195e-4adc-b049-6047db4c05f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
